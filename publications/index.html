<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>publications | Northeastern Human-Centered AI Lab</title> <meta name="author" content=" Northeastern Human-Centered AI Lab"> <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar."> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://alshedivat.github.io/publications/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container header-container"> <div class="navbar-header"> <svg aria-label="Northeastern University" title="Northeastern University" width="195" height="18" viewbox="0 0 195 18" fill="none" style="margin-top: 10px"> <path d="M189.958 15.114l3.166-7.2c.599-1.389.856-1.736 1.455-1.91v-.52h-3.337v.52c1.112.26 1.198.781.684 1.996l-1.283 3.123-1.54-3.557c-.343-.78-.257-1.301.855-1.388v-.52h-4.449v.52c.513.173.77.347 1.198 1.301l2.823 6.16-.513 1.041c-.257.608-.513 1.041-.77 1.302-.171-.694-.599-1.041-1.198-1.041s-1.112.433-1.112 1.214c0 .781.684 1.388 1.369 1.388 1.112 0 1.797-.52 2.652-2.429zm-4.535-2.169l-.257-.52c-.427.173-.855.347-1.197.347-.771 0-1.027-.434-1.027-.955V6.612h2.139v-.955h-2.139V4.096h-.343l-3.08 1.995v.52h1.198v5.64c0 1.128.599 1.735 1.882 1.735 1.027-.087 2.054-.347 2.824-1.04zm-6.417.26c-1.027-.173-1.198-.347-1.198-1.301V5.31h-.856l-2.481 1.649v.347h1.198v4.598c0 .954-.172 1.128-1.198 1.301v.52h4.535v-.52zm-2.482-9.196c.685 0 1.284-.607 1.284-1.301s-.514-1.215-1.198-1.215c-.77 0-1.284.607-1.284 1.301.086.694.514 1.215 1.198 1.215zm-2.909 7.288c0-1.562-1.284-2.082-2.567-2.516-1.198-.434-2.054-.608-2.054-1.562 0-.52.343-.954 1.027-.954.856 0 1.626.52 2.567 1.561l.428-.173-.599-2.082h-.257l-.342.26c-.513-.174-1.027-.347-1.626-.347-1.797 0-2.995 1.041-2.995 2.603 0 1.561 1.284 2.082 2.567 2.429 1.198.434 2.054.607 2.054 1.562 0 .607-.428 1.04-1.198 1.04-1.112 0-1.968-.78-3.08-2.082l-.428.174.684 2.69h.257l.514-.348c.598.26 1.197.434 1.882.434 1.711 0 3.166-1.04 3.166-2.69zm-8.813 1.995c-1.113-.173-1.284-.434-1.284-1.475V8.26a6.397 6.397 0 011.027-1.388c0 .694.428 1.128 1.027 1.128s1.112-.434 1.112-1.388c0-.781-.428-1.215-1.198-1.215-.856 0-1.455.694-2.053 1.735V5.397h-.771l-2.481 1.649v.347h1.198v4.598c0 .954-.171 1.214-1.112 1.301v.52h4.535v-.52zm-10.696-4.685c0-1.388.599-2.255 1.711-2.255.77 0 1.284.607 1.455 1.648l-3.166 1.128v-.52zm5.305 3.644l-.428-.347c-.428.52-1.112.868-1.968.868-1.54 0-2.481-1.215-2.738-2.777l5.048-1.735c-.085-1.822-1.454-2.776-3.08-2.776-2.396 0-4.107 1.909-4.107 4.338 0 2.342 1.54 4.164 4.107 4.164 1.626 0 2.652-.694 3.166-1.735zm-8.813-4.164c.598-1.388.855-1.736 1.454-1.909v-.52h-3.337v.52c1.112.26 1.198.78.685 1.995l-1.284 3.124-1.626-3.644c-.342-.781-.256-1.301.856-1.388v-.52h-4.449v.52c.513.173.77.347 1.197 1.301l2.91 6.333h.855l2.739-5.812zm-7.787 5.205c-1.027-.173-1.198-.347-1.198-1.301V5.397h-.856l-2.481 1.649v.347h1.198v4.598c0 .954-.171 1.128-1.198 1.301v.52h4.535v-.52zm-2.396-9.196c.685 0 1.284-.608 1.284-1.302 0-.694-.514-1.214-1.198-1.214-.77 0-1.284.607-1.284 1.301s.514 1.215 1.198 1.215zm-8.557 9.196c-.941-.173-1.112-.347-1.112-1.301V8c.856-.78 1.54-1.128 2.139-1.128.856 0 1.027.434 1.113 1.215v3.904c0 .954-.172 1.214-1.113 1.301v.52h4.364v-.52c-.941-.173-1.112-.347-1.112-1.301V7.913c0-1.388-.599-2.342-2.311-2.342-1.026 0-2.053.694-3.08 1.561V5.484h-.77l-2.481 1.648v.347h1.197v4.599c0 .954-.171 1.214-1.112 1.3v.521h4.364l-.086-.607zM113.29 3.228v5.119c0 3.297 1.712 5.64 6.076 5.64s6.075-2.343 5.989-5.64V4.183c0-1.996.514-2.516 1.541-2.777v-.52h-4.108v.52c.942.26 1.541.781 1.541 2.777v4.164c0 2.95-1.541 4.251-4.364 4.251-2.824 0-4.364-1.301-4.364-4.251V3.14c0-1.3.342-1.561 1.454-1.648V.886h-5.134v.607c1.027.26 1.369.434 1.369 1.735zM99.77 13.379c-.94-.174-1.112-.347-1.112-1.301V8.087c.856-.781 1.541-1.128 2.14-1.128.855 0 1.026.434 1.112 1.214v3.905c0 .954-.171 1.214-1.112 1.3v.521h4.363v-.52c-.941-.174-1.112-.347-1.112-1.301V8c0-1.388-.599-2.343-2.31-2.343-1.027 0-2.054.695-3.08 1.562V5.571h-.77l-2.482 1.648v.347h1.198v4.598c0 .955-.171 1.215-1.113 1.302v.52h4.364l-.085-.607zm-6.759 0c-1.112-.174-1.283-.434-1.283-1.475V8.347a6.393 6.393 0 011.026-1.388c0 .694.428 1.128 1.027 1.128s1.112-.434 1.112-1.388c0-.781-.427-1.215-1.198-1.215-.855 0-1.454.694-2.053 1.735V5.484h-.77L88.39 7.132v.347h1.198v4.599c0 .954-.17 1.214-1.112 1.3v.521h4.535v-.52zM82.401 8.78c0-1.388.599-2.256 1.711-2.256.77 0 1.284.607 1.455 1.648L82.4 9.301v-.52zm5.305 3.644l-.428-.347c-.428.52-1.112.867-1.968.867-1.54 0-2.481-1.215-2.738-2.776l5.048-1.735c-.085-1.822-1.454-2.777-3.08-2.777-2.396 0-4.107 1.91-4.107 4.252 0 2.342 1.54 4.164 4.107 4.164 1.626 0 2.567-.694 3.166-1.648zm-7.872.78l-.257-.607c-.428.174-.856.347-1.198.347-.77 0-1.027-.434-1.027-.954V6.785h2.14v-.954h-2.14V4.269h-.342l-3.08 1.996v.52h1.197v5.64c0 1.127.6 1.735 1.883 1.735 1.112 0 2.054-.347 2.824-.955zm-6.418-1.735c0-1.561-1.283-2.082-2.567-2.516-1.198-.434-2.053-.607-2.053-1.561 0-.52.342-.955 1.026-.955.856 0 1.626.52 2.567 1.562l.428-.174-.684-2.169h-.257l-.342.26c-.514-.173-1.027-.346-1.626-.346-1.797 0-2.995 1.04-2.995 2.602 0 1.562 1.284 2.083 2.567 2.43 1.198.434 2.054.607 2.054 1.561 0 .608-.428 1.041-1.198 1.041-1.113 0-1.968-.78-3.08-2.082l-.428.174.684 2.69h.257l.513-.348c.6.26 1.198.434 1.883.434 1.882.087 3.251-.954 3.251-2.603zm-13.006.347c0-.867.428-1.301 2.396-1.822v2.516c-.514.347-.856.52-1.284.52-.77 0-1.112-.433-1.112-1.214zm3.68 2.256c.77 0 1.54-.347 2.053-.694l-.171-.52c-.856.173-1.112 0-1.112-.521V7.74c0-1.388-.6-2.083-2.482-2.083-2.14 0-3.765 1.215-3.765 2.256 0 .52.342.955.941.955.685 0 1.027-.434 1.113-.955.085-.52-.086-.954-.343-1.128.428-.173.856-.347 1.284-.347.77 0 1.112.26 1.112.955v1.735c-2.995.78-4.45 1.475-4.45 3.036 0 1.215.771 1.909 2.054 1.909.77 0 1.712-.347 2.482-.954.171.607.599.954 1.283.954zM52.11 8.781c0-1.388.6-2.256 1.711-2.256.77 0 1.284.607 1.455 1.648L52.11 9.301v-.52zm5.305 3.644l-.428-.347c-.427.52-1.112.867-1.968.867-1.54 0-2.481-1.215-2.738-2.776l5.049-1.735c-.086-1.822-1.455-2.777-3.08-2.777-2.397 0-4.108 1.91-4.108 4.338 0 2.343 1.54 4.165 4.107 4.165 1.626 0 2.567-.694 3.166-1.735zm-13.52 1.04c-.94-.086-1.112-.346-1.112-1.3V8.172c.856-.78 1.455-1.127 2.14-1.127.855 0 1.026.433 1.112 1.214v3.904c0 .955-.171 1.215-1.112 1.302v.52h4.363v-.52c-.94-.174-1.112-.347-1.112-1.302V8.087c0-1.388-.599-2.343-2.31-2.343-1.027 0-2.054.608-3.08 1.475V.365h-.6l-2.823 1.822v.347h1.198v9.63c0 .955-.171 1.215-1.113 1.302v.52h4.364l.086-.52zm-4.877-.173l-.256-.52c-.428.173-.856.347-1.198.347-.77 0-1.027-.434-1.027-.955V6.96h2.14v-.954h-2.14V4.442h-.342l-3.08 1.995v.52h1.197v5.64c0 1.128.6 1.735 1.883 1.735a5.616 5.616 0 002.823-1.04zm-8.3.26c-1.112-.173-1.283-.433-1.283-1.474V8.52a6.4 6.4 0 011.027-1.388c0 .694.428 1.128 1.026 1.128.6 0 1.113-.434 1.113-1.388 0-.78-.428-1.215-1.198-1.215-.856 0-1.455.695-2.054 1.736V5.657h-.77l-2.481 1.649v.347h1.198v4.598c0 .954-.171 1.215-1.113 1.301v.521h4.535v-.52zM18.482 9.128c0-1.562.685-2.516 2.054-2.516 1.797 0 2.31 2.256 2.31 4.251 0 1.562-.684 2.516-2.053 2.516-1.797 0-2.31-2.256-2.31-4.251zm6.503.78c0-2.255-1.54-4.164-4.192-4.164-2.738 0-4.364 1.996-4.364 4.338 0 2.256 1.54 4.164 4.193 4.164 2.652 0 4.363-1.995 4.363-4.337zM13.862 4.53c0-1.996.513-2.516 1.54-2.777v-.52h-4.107v.52c.941.26 1.54.781 1.54 2.777v6.073l-8.642-8.85c-.514-.52-.685-.52-1.027-.52H0v.52c.685.087 1.112.347 1.882 1.128.257.174.514.52.514.955v6.853c0 1.996-.514 2.516-1.54 2.777v.52h4.107v-.52c-.941-.174-1.54-.694-1.54-2.69V4.27l9.754 9.89h.685V4.53z" fill="currentColor"></path> </svg> <a class="navbar-brand title font-weight-lighter" href="/">Northeastern Human-Centered AI Lab</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/team">team</a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/opening/">opening</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p> </header> <article> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2"><img src="/assets/img/3.jpg" class="publication-image" alt="Description of the image"></div> <div id="10.1145/3544548.3581290" class="col-sm-8"> <div class="title">Model Sketching: Centering Concepts in Early-Stage Machine Learning Model Design</div> <div class="author"> Michelle S. Lam, Zixian Ma, Anne Li, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Izequiel Freitas, Dakuo Wang, James A. Landay, Michael S. Bernstein' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</em>, 2023</div> <div class="periodical"></div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Machine learning practitioners often end up tunneling on low-level technical details like model architectures and performance metrics. Could early model development instead focus on high-level questions of which factors a model ought to pay attention to? Inspired by the practice of sketching in design, which distills ideas to their minimal representation, we introduce model sketching: a technical framework for iteratively and rapidly authoring functional approximations of a machine learning model’s decision-making logic. Model sketching refocuses practitioner attention on composing high-level, human-understandable concepts that the model is expected to reason over (e.g., profanity, racism, or sarcasm in a content moderation task) using zero-shot concept instantiation. In an evaluation with 17 ML practitioners, model sketching reframed thinking from implementation to higher-level exploration, prompted iteration on a broader range of model designs, and helped identify gaps in the problem formulation—all in a fraction of the time ordinarily required to build a model.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3544548.3581290</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Lam, Michelle S. and Ma, Zixian and Li, Anne and Freitas, Izequiel and Wang, Dakuo and Landay, James A. and Bernstein, Michael S.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Model Sketching: Centering Concepts in Early-Stage Machine Learning Model Design}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450394215}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3544548.3581290}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3544548.3581290}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems}</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{741}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{24}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Hamburg, Germany}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CHI '23}</span><span class="p">,</span>
  <span class="na">img</span> <span class="p">=</span> <span class="s">{/assets/img/3.jpg}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2"><img src="/assets/img/1.jpg" class="publication-image" alt="Description of the image"></div> <div id="10.1145/3544548.3581219" class="col-sm-8"> <div class="title">Exploring the Use of Personalized AI for Identifying Misinformation on Social Media</div> <div class="author"> Farnaz Jahanbakhsh, Yannis Katsis, <em>Dakuo Wang</em>, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Lucian Popa, Michael Muller' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</em>, 2023</div> <div class="periodical"></div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>This work aims to explore how human assessments and AI predictions can be combined to identify misinformation on social media. To do so, we design a personalized AI which iteratively takes as training data a single user’s assessment of content and predicts how the same user would assess other content. We conduct a user study in which participants interact with a personalized AI that learns their assessments of a feed of tweets, shows its predictions of whether a user would find other tweets (in)accurate, and evolves according to the user feedback. We study how users perceive such an AI, and whether the AI predictions influence users’ judgment. We find that this influence does exist and it grows larger over time, but it is reduced when users provide reasoning for their assessment. We draw from our empirical observations to identify design implications and directions for future work.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2"><img src="/assets/img/1.jpg" class="publication-image" alt="Description of the image"></div> <div id="isaza2023fairy" class="col-sm-8"> <div class="title">Are Fairy Tales Fair? Analyzing Gender Bias in Temporal Narrative Event Chains of Children’s Fairy Tales</div> <div class="author"> Paulina Toro Isaza, Guangxuan Xu, Akintoye Oloko, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Yufang Hou, Nanyun Peng, Dakuo Wang' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>arXiv preprint arXiv:2305.16641</em>, 2023</div> <div class="periodical"></div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">isaza2023fairy</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Are Fairy Tales Fair? Analyzing Gender Bias in Temporal Narrative Event Chains of Children's Fairy Tales}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Isaza, Paulina Toro and Xu, Guangxuan and Oloko, Akintoye and Hou, Yufang and Peng, Nanyun and Wang, Dakuo}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2305.16641}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2"><img src="/assets/img/1.jpg" class="publication-image" alt="Description of the image"></div> <div id="10.1145/3491102.3517615" class="col-sm-8"> <div class="title">Telling Stories from Computational Notebooks: AI-Assisted Presentation Slides Creation for Presenting Data Science Work</div> <div class="author"> Chengbo Zheng, <em>Dakuo Wang</em>, April Yi Wang, and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Xiaojuan Ma' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems</em>, 2022</div> <div class="periodical"></div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Creating presentation slides is a critical but time-consuming task for data scientists. While researchers have proposed many AI techniques to lift data scientists’ burden on data preparation and model selection, few have targeted the presentation creation task. Based on the needs identified from a formative study, this paper presents NB2Slides, an AI system that facilitates users to compose presentations of their data science work. NB2Slides uses deep learning methods as well as example-based prompts to generate slides from computational notebooks, and take users’ input (e.g., audience background) to structure the slides. NB2Slides also provides an interactive visualization that links the slides with the notebook to help users further edit the slides. A follow-up user evaluation with 12 data scientists shows that participants believed NB2Slides can improve efficiency and reduces the complexity of creating slides. Yet, participants questioned the future of full automation and suggested a human-AI collaboration paradigm.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3491102.3517615</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zheng, Chengbo and Wang, Dakuo and Wang, April Yi and Ma, Xiaojuan}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Telling Stories from Computational Notebooks: AI-Assisted Presentation Slides Creation for Presenting Data Science Work}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450391573}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3491102.3517615}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3491102.3517615}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems}</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{53}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{20}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{New Orleans, LA, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CHI '22}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2"><img src="/assets/img/1.jpg" class="publication-image" alt="Description of the image"></div> <div id="10.1145/3491102.3517479" class="col-sm-8"> <div class="title">StoryBuddy: A Human-AI Collaborative Chatbot for Parent-Child Interactive Storytelling with Flexible Parental Involvement</div> <div class="author"> Zheng Zhang, Ying Xu, Yanhao Wang, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Bingsheng Yao, Daniel Ritchie, Tongshuang Wu, Mo Yu, Dakuo Wang, Toby Jia-Jun Li' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems</em>, 2022</div> <div class="periodical"></div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Despite its benefits for children’s skill development and parent-child bonding, many parents do not often engage in interactive storytelling by having story-related dialogues with their child due to limited availability or challenges in coming up with appropriate questions. While recent advances made AI generation of questions from stories possible, the fully-automated approach excludes parent involvement, disregards educational goals, and underoptimizes for child engagement. Informed by need-finding interviews and participatory design (PD) results, we developed StoryBuddy, an AI-enabled system for parents to create interactive storytelling experiences. StoryBuddy’s design highlighted the need for accommodating dynamic user needs between the desire for parent involvement and parent-child bonding and the goal of minimizing parent intervention when busy. The PD revealed varied assessment and educational goals of parents, which StoryBuddy addressed by supporting configuring question types and tracking child progress. A user study validated StoryBuddy’s usability and suggested design insights for future parent-AI collaboration systems.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3491102.3517479</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Zheng and Xu, Ying and Wang, Yanhao and Yao, Bingsheng and Ritchie, Daniel and Wu, Tongshuang and Yu, Mo and Wang, Dakuo and Li, Toby Jia-Jun}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{StoryBuddy: A Human-AI Collaborative Chatbot for Parent-Child Interactive Storytelling with Flexible Parental Involvement}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450391573}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3491102.3517479}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3491102.3517479}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems}</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{218}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{21}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{child-agent interactions, voice user interfaces, human-AI collaboration, interactive storytelling, dialogic reading, co-reading}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{New Orleans, LA, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CHI '22}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2"><img src="/assets/img/1.jpg" class="publication-image" alt="Description of the image"></div> <div id="yao-etal-2022-ais" class="col-sm-8"> <div class="title">It is AI’s Turn to Ask Humans a Question: Question-Answer Pair Generation for Children’s Story Books</div> <div class="author"> <a href="https://www.bingshengyao.com" rel="external nofollow noopener" target="_blank">Bingsheng Yao</a>, <em>Dakuo Wang</em>, Tongshuang Wu, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Zheng Zhang, Toby Li, Mo Yu, Ying Xu' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, May 2022</div> <div class="periodical"></div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="abstract hidden"> <p>Existing question answering (QA) techniques are created mainly to answer questions asked by humans. But in educational applications, teachers often need to decide what questions they should ask, in order to help students to improve their narrative understanding capabilities. We design an automated question-answer generation (QAG) system for this education scenario: given a story book at the kindergarten to eighth-grade level as input, our system can automatically generate QA pairs that are capable of testing a variety of dimensions of a student’s comprehension skills. Our proposed QAG model architecture is demonstrated using a new expert-annotated FairytaleQA dataset, which has 278 child-friendly storybooks with 10,580 QA pairs. Automatic and human evaluations show that our model outperforms state-of-the-art QAG baseline systems. On top of our QAG system, we also start to build an interactive story-telling application for the future real-world deployment in this educational scenario.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2"><img src="/assets/img/1.jpg" class="publication-image" alt="Description of the image"></div> <div id="xu-etal-2022-fantastic" class="col-sm-8"> <div class="title">Fantastic Questions and Where to Find Them: FairytaleQA – An Authentic Dataset for Narrative Comprehension</div> <div class="author"> Ying Xu, <em>Dakuo Wang</em>, Mo Yu, and <span class="more-authors" title="click to view 15 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '15 more authors' ? 'Daniel Ritchie, Bingsheng Yao, Tongshuang Wu, Zheng Zhang, Toby Li, Nora Bradford, Branda Sun, Tran Hoang, Yisi Sang, Yufang Hou, Xiaojuan Ma, Diyi Yang, Nanyun Peng, Zhou Yu, Mark Warschauer' : '15 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">15 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, May 2022</div> <div class="periodical"></div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>Question answering (QA) is a fundamental means to facilitate assessment and training of narrative comprehension skills for both machines and young children, yet there is scarcity of high-quality QA datasets carefully designed to serve this purpose. In particular, existing datasets rarely distinguish fine-grained reading skills, such as the understanding of varying narrative elements. Drawing on the reading education research, we introduce FairytaleQA, a dataset focusing on narrative comprehension of kindergarten to eighth-grade students. Generated by educational experts based on an evidence-based theoretical framework, FairytaleQA consists of 10,580 explicit and implicit questions derived from 278 children-friendly stories, covering seven types of narrative elements or relations. Our dataset is valuable in two folds: First, we ran existing QA models on our dataset and confirmed that this annotation helps assess models’ fine-grained learning skills. Second, the dataset supports question generation (QG) task in the education domain. Through benchmarking with QG models, we show that the QG model trained on FairytaleQA is capable of asking high-quality and more diverse questions.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">xu-etal-2022-fantastic</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Fantastic Questions and Where to Find Them: {F}airytale{QA} {--} An Authentic Dataset for Narrative Comprehension}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Xu, Ying and Wang, Dakuo and Yu, Mo and Ritchie, Daniel and Yao, Bingsheng and Wu, Tongshuang and Zhang, Zheng and Li, Toby and Bradford, Nora and Sun, Branda and Hoang, Tran and Sang, Yisi and Hou, Yufang and Ma, Xiaojuan and Yang, Diyi and Peng, Nanyun and Yu, Zhou and Warschauer, Mark}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">may</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Dublin, Ireland}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2022.acl-long.34}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2022.acl-long.34}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{447--460}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2"><img src="/assets/img/1.jpg" class="publication-image" alt="Description of the image"></div> <div id="10.1145/3377325.3377501" class="col-sm-8"> <div class="title">Trust in AutoML: Exploring Information Needs for Establishing Trust in Automated Machine Learning Systems</div> <div class="author"> Jaimie Drozdal, Justin Weisz, <em>Dakuo Wang</em>, and <span class="more-authors" title="click to view 6 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '6 more authors' ? 'Gaurav Dass, Bingsheng Yao, Changruo Zhao, Michael Muller, Lin Ju, Hui Su' : '6 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">6 more authors</span> </div> <div class="periodical"> <em>In Proceedings of the 25th International Conference on Intelligent User Interfaces</em>, May 2020</div> <div class="periodical"></div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="abstract hidden"> <p>We explore trust in a relatively new area of data science: Automated Machine Learning (AutoML). In AutoML, AI methods are used to generate and optimize machine learning models by automatically engineering features, selecting models, and optimizing hyperparameters. In this paper, we seek to understand what kinds of information influence data scientists’ trust in the models produced by AutoML? We operationalize trust as a willingness to deploy a model produced using automated methods. We report results from three studies - qualitative interviews, a controlled experiment, and a card-sorting task - to understand the information needs of data scientists for establishing trust in AutoML systems. We find that including transparency features in an AutoML tool increased user trust and understandability in the tool; and out of all proposed features, model performance metrics and visualizations are the most important information to data scientists when establishing their trust with an AutoML tool.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">10.1145/3377325.3377501</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Drozdal, Jaimie and Weisz, Justin and Wang, Dakuo and Dass, Gaurav and Yao, Bingsheng and Zhao, Changruo and Muller, Michael and Ju, Lin and Su, Hui}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Trust in AutoML: Exploring Information Needs for Establishing Trust in Automated Machine Learning Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450371186}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3377325.3377501}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3377325.3377501}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 25th International Conference on Intelligent User Interfaces}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{297–307}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{automated artificial intelligence, AutoAI, automated data science, AutoML, trust, automated machine learning, AutoDS}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Cagliari, Italy}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{IUI '20}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <div class="container" style="padding-top: 50px"> <footer class="py-10 bg-gray-800 fixed-bottom"> <div class="px-4 text-white lg:px-16"> <div class="-mx-2 flex flex-wrap justify-between space-y-8 lg:space-y-0"> <div class="w-full px-2 lg:w-auto"> <a class="inline-block hover:text-gray-300 focus:outline-none focus:ring focus:ring-black" href="#"> <svg aria-label="Northeastern University" title="Northeastern University" width="195" height="18" viewbox="0 0 195 18" fill="none" style="margin-top: 10px"> <path d="M189.958 15.114l3.166-7.2c.599-1.389.856-1.736 1.455-1.91v-.52h-3.337v.52c1.112.26 1.198.781.684 1.996l-1.283 3.123-1.54-3.557c-.343-.78-.257-1.301.855-1.388v-.52h-4.449v.52c.513.173.77.347 1.198 1.301l2.823 6.16-.513 1.041c-.257.608-.513 1.041-.77 1.302-.171-.694-.599-1.041-1.198-1.041s-1.112.433-1.112 1.214c0 .781.684 1.388 1.369 1.388 1.112 0 1.797-.52 2.652-2.429zm-4.535-2.169l-.257-.52c-.427.173-.855.347-1.197.347-.771 0-1.027-.434-1.027-.955V6.612h2.139v-.955h-2.139V4.096h-.343l-3.08 1.995v.52h1.198v5.64c0 1.128.599 1.735 1.882 1.735 1.027-.087 2.054-.347 2.824-1.04zm-6.417.26c-1.027-.173-1.198-.347-1.198-1.301V5.31h-.856l-2.481 1.649v.347h1.198v4.598c0 .954-.172 1.128-1.198 1.301v.52h4.535v-.52zm-2.482-9.196c.685 0 1.284-.607 1.284-1.301s-.514-1.215-1.198-1.215c-.77 0-1.284.607-1.284 1.301.086.694.514 1.215 1.198 1.215zm-2.909 7.288c0-1.562-1.284-2.082-2.567-2.516-1.198-.434-2.054-.608-2.054-1.562 0-.52.343-.954 1.027-.954.856 0 1.626.52 2.567 1.561l.428-.173-.599-2.082h-.257l-.342.26c-.513-.174-1.027-.347-1.626-.347-1.797 0-2.995 1.041-2.995 2.603 0 1.561 1.284 2.082 2.567 2.429 1.198.434 2.054.607 2.054 1.562 0 .607-.428 1.04-1.198 1.04-1.112 0-1.968-.78-3.08-2.082l-.428.174.684 2.69h.257l.514-.348c.598.26 1.197.434 1.882.434 1.711 0 3.166-1.04 3.166-2.69zm-8.813 1.995c-1.113-.173-1.284-.434-1.284-1.475V8.26a6.397 6.397 0 011.027-1.388c0 .694.428 1.128 1.027 1.128s1.112-.434 1.112-1.388c0-.781-.428-1.215-1.198-1.215-.856 0-1.455.694-2.053 1.735V5.397h-.771l-2.481 1.649v.347h1.198v4.598c0 .954-.171 1.214-1.112 1.301v.52h4.535v-.52zm-10.696-4.685c0-1.388.599-2.255 1.711-2.255.77 0 1.284.607 1.455 1.648l-3.166 1.128v-.52zm5.305 3.644l-.428-.347c-.428.52-1.112.868-1.968.868-1.54 0-2.481-1.215-2.738-2.777l5.048-1.735c-.085-1.822-1.454-2.776-3.08-2.776-2.396 0-4.107 1.909-4.107 4.338 0 2.342 1.54 4.164 4.107 4.164 1.626 0 2.652-.694 3.166-1.735zm-8.813-4.164c.598-1.388.855-1.736 1.454-1.909v-.52h-3.337v.52c1.112.26 1.198.78.685 1.995l-1.284 3.124-1.626-3.644c-.342-.781-.256-1.301.856-1.388v-.52h-4.449v.52c.513.173.77.347 1.197 1.301l2.91 6.333h.855l2.739-5.812zm-7.787 5.205c-1.027-.173-1.198-.347-1.198-1.301V5.397h-.856l-2.481 1.649v.347h1.198v4.598c0 .954-.171 1.128-1.198 1.301v.52h4.535v-.52zm-2.396-9.196c.685 0 1.284-.608 1.284-1.302 0-.694-.514-1.214-1.198-1.214-.77 0-1.284.607-1.284 1.301s.514 1.215 1.198 1.215zm-8.557 9.196c-.941-.173-1.112-.347-1.112-1.301V8c.856-.78 1.54-1.128 2.139-1.128.856 0 1.027.434 1.113 1.215v3.904c0 .954-.172 1.214-1.113 1.301v.52h4.364v-.52c-.941-.173-1.112-.347-1.112-1.301V7.913c0-1.388-.599-2.342-2.311-2.342-1.026 0-2.053.694-3.08 1.561V5.484h-.77l-2.481 1.648v.347h1.197v4.599c0 .954-.171 1.214-1.112 1.3v.521h4.364l-.086-.607zM113.29 3.228v5.119c0 3.297 1.712 5.64 6.076 5.64s6.075-2.343 5.989-5.64V4.183c0-1.996.514-2.516 1.541-2.777v-.52h-4.108v.52c.942.26 1.541.781 1.541 2.777v4.164c0 2.95-1.541 4.251-4.364 4.251-2.824 0-4.364-1.301-4.364-4.251V3.14c0-1.3.342-1.561 1.454-1.648V.886h-5.134v.607c1.027.26 1.369.434 1.369 1.735zM99.77 13.379c-.94-.174-1.112-.347-1.112-1.301V8.087c.856-.781 1.541-1.128 2.14-1.128.855 0 1.026.434 1.112 1.214v3.905c0 .954-.171 1.214-1.112 1.3v.521h4.363v-.52c-.941-.174-1.112-.347-1.112-1.301V8c0-1.388-.599-2.343-2.31-2.343-1.027 0-2.054.695-3.08 1.562V5.571h-.77l-2.482 1.648v.347h1.198v4.598c0 .955-.171 1.215-1.113 1.302v.52h4.364l-.085-.607zm-6.759 0c-1.112-.174-1.283-.434-1.283-1.475V8.347a6.393 6.393 0 011.026-1.388c0 .694.428 1.128 1.027 1.128s1.112-.434 1.112-1.388c0-.781-.427-1.215-1.198-1.215-.855 0-1.454.694-2.053 1.735V5.484h-.77L88.39 7.132v.347h1.198v4.599c0 .954-.17 1.214-1.112 1.3v.521h4.535v-.52zM82.401 8.78c0-1.388.599-2.256 1.711-2.256.77 0 1.284.607 1.455 1.648L82.4 9.301v-.52zm5.305 3.644l-.428-.347c-.428.52-1.112.867-1.968.867-1.54 0-2.481-1.215-2.738-2.776l5.048-1.735c-.085-1.822-1.454-2.777-3.08-2.777-2.396 0-4.107 1.91-4.107 4.252 0 2.342 1.54 4.164 4.107 4.164 1.626 0 2.567-.694 3.166-1.648zm-7.872.78l-.257-.607c-.428.174-.856.347-1.198.347-.77 0-1.027-.434-1.027-.954V6.785h2.14v-.954h-2.14V4.269h-.342l-3.08 1.996v.52h1.197v5.64c0 1.127.6 1.735 1.883 1.735 1.112 0 2.054-.347 2.824-.955zm-6.418-1.735c0-1.561-1.283-2.082-2.567-2.516-1.198-.434-2.053-.607-2.053-1.561 0-.52.342-.955 1.026-.955.856 0 1.626.52 2.567 1.562l.428-.174-.684-2.169h-.257l-.342.26c-.514-.173-1.027-.346-1.626-.346-1.797 0-2.995 1.04-2.995 2.602 0 1.562 1.284 2.083 2.567 2.43 1.198.434 2.054.607 2.054 1.561 0 .608-.428 1.041-1.198 1.041-1.113 0-1.968-.78-3.08-2.082l-.428.174.684 2.69h.257l.513-.348c.6.26 1.198.434 1.883.434 1.882.087 3.251-.954 3.251-2.603zm-13.006.347c0-.867.428-1.301 2.396-1.822v2.516c-.514.347-.856.52-1.284.52-.77 0-1.112-.433-1.112-1.214zm3.68 2.256c.77 0 1.54-.347 2.053-.694l-.171-.52c-.856.173-1.112 0-1.112-.521V7.74c0-1.388-.6-2.083-2.482-2.083-2.14 0-3.765 1.215-3.765 2.256 0 .52.342.955.941.955.685 0 1.027-.434 1.113-.955.085-.52-.086-.954-.343-1.128.428-.173.856-.347 1.284-.347.77 0 1.112.26 1.112.955v1.735c-2.995.78-4.45 1.475-4.45 3.036 0 1.215.771 1.909 2.054 1.909.77 0 1.712-.347 2.482-.954.171.607.599.954 1.283.954zM52.11 8.781c0-1.388.6-2.256 1.711-2.256.77 0 1.284.607 1.455 1.648L52.11 9.301v-.52zm5.305 3.644l-.428-.347c-.427.52-1.112.867-1.968.867-1.54 0-2.481-1.215-2.738-2.776l5.049-1.735c-.086-1.822-1.455-2.777-3.08-2.777-2.397 0-4.108 1.91-4.108 4.338 0 2.343 1.54 4.165 4.107 4.165 1.626 0 2.567-.694 3.166-1.735zm-13.52 1.04c-.94-.086-1.112-.346-1.112-1.3V8.172c.856-.78 1.455-1.127 2.14-1.127.855 0 1.026.433 1.112 1.214v3.904c0 .955-.171 1.215-1.112 1.302v.52h4.363v-.52c-.94-.174-1.112-.347-1.112-1.302V8.087c0-1.388-.599-2.343-2.31-2.343-1.027 0-2.054.608-3.08 1.475V.365h-.6l-2.823 1.822v.347h1.198v9.63c0 .955-.171 1.215-1.113 1.302v.52h4.364l.086-.52zm-4.877-.173l-.256-.52c-.428.173-.856.347-1.198.347-.77 0-1.027-.434-1.027-.955V6.96h2.14v-.954h-2.14V4.442h-.342l-3.08 1.995v.52h1.197v5.64c0 1.128.6 1.735 1.883 1.735a5.616 5.616 0 002.823-1.04zm-8.3.26c-1.112-.173-1.283-.433-1.283-1.474V8.52a6.4 6.4 0 011.027-1.388c0 .694.428 1.128 1.026 1.128.6 0 1.113-.434 1.113-1.388 0-.78-.428-1.215-1.198-1.215-.856 0-1.455.695-2.054 1.736V5.657h-.77l-2.481 1.649v.347h1.198v4.598c0 .954-.171 1.215-1.113 1.301v.521h4.535v-.52zM18.482 9.128c0-1.562.685-2.516 2.054-2.516 1.797 0 2.31 2.256 2.31 4.251 0 1.562-.684 2.516-2.053 2.516-1.797 0-2.31-2.256-2.31-4.251zm6.503.78c0-2.255-1.54-4.164-4.192-4.164-2.738 0-4.364 1.996-4.364 4.338 0 2.256 1.54 4.164 4.193 4.164 2.652 0 4.363-1.995 4.363-4.337zM13.862 4.53c0-1.996.513-2.516 1.54-2.777v-.52h-4.107v.52c.941.26 1.54.781 1.54 2.777v6.073l-8.642-8.85c-.514-.52-.685-.52-1.027-.52H0v.52c.685.087 1.112.347 1.882 1.128.257.174.514.52.514.955v6.853c0 1.996-.514 2.516-1.54 2.777v.52h4.107v-.52c-.941-.174-1.54-.694-1.54-2.69V4.27l9.754 9.89h.685V4.53z" fill="currentColor"></path> </svg> </a> <div class="mt-0" style="color: white"> <div class="navbar-brand social"> <a href="https://github.com/NEU-HAI-Lab" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://twitter.com/dakuowang" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a> </div> © 2023 <a href="https://www.dakuowang.com/" target="_blank" rel="external nofollow noopener">Dakuo Wang</a>, Associate Professor, <a href="https://www.khoury.northeastern.edu/" target="_blank" rel="external nofollow noopener">Khoury College of Computer and Information Sciences</a>, <a href="https://www.northeastern.edu/" target="_blank" rel="external nofollow noopener">Northeastern University</a>. Compiled on Sun, 22 Oct 2023 22:14:34 +0000. </div> </div> </div> </div> </footer> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js"></script> <script defer src="/assets/js/common.js"></script> <script defer src="/assets/js/copy_code.js" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>